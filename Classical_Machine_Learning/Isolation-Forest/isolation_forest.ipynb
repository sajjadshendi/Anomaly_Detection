{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:03.897106Z",
     "start_time": "2024-08-28T11:36:03.849995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Import necessary libraries\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from utils import isolation_forest_algorithm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:04.231095Z",
     "start_time": "2024-08-28T11:36:04.214253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#path of folders and datasets\n",
    "sheet_names = []\n",
    "xlsx_dolder = None\n",
    "result_folder = None\n",
    "cleaning_condition = None"
   ],
   "id": "12c45a7be5106b5a",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:04.709375Z",
     "start_time": "2024-08-28T11:36:04.699923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#parameters\n",
    "test_sheet = None"
   ],
   "id": "5ee9444c63ef5334",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:05.241613Z",
     "start_time": "2024-08-28T11:36:05.223969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that makes csv datasets from multi-sheet excels\n",
    "def make_dataset(input_folder, output_folder, sheet_names):\n",
    "    contents = os.listdir(input_folder)\n",
    "    root = input_folder\n",
    "    total_data = {}\n",
    "    for sheet in sheet_names:\n",
    "        total_data[sheet] = pd.DataFrame()\n",
    "    for content in contents:\n",
    "        adr = root + \"/\" + content\n",
    "        if(os.path.isfile(adr)):\n",
    "            file_data = pd.read_excel(adr, sheet_name = sheet_names)\n",
    "            for sheet in sheet_names:\n",
    "                total_data[sheet] = pd.concat([total_data[sheet], file_data[sheet]])\n",
    "    for sheet in sheet_names:\n",
    "        total_data[sheet] = total_data[sheet].reset_index(drop = True)\n",
    "        total_data[sheet].to_csv(output_folder + \"/\" + sheet + \".csv\", index = False)\n",
    "    return total_data"
   ],
   "id": "b30361a53c79b70e",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:06.179532Z",
     "start_time": "2024-08-28T11:36:06.157262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that loads all sheet datasets from csv files and puts them in a dict\n",
    "def load_dataset(data_folder, sheet_names):\n",
    "    data = {}\n",
    "    for sheet in sheet_names:\n",
    "        path = data_folder + \"/\" + sheet + \".csv\"\n",
    "        #with shuffling\n",
    "        data[sheet] = pd.read_csv(path, low_memory=False).sample(frac = 1).reset_index(drop = True)\n",
    "        #without shuffling\n",
    "        #data[sheet] = pd.read_csv(path, low_memory=False)\n",
    "    return data"
   ],
   "id": "8307856dbc7138b4",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:08.409383Z",
     "start_time": "2024-08-28T11:36:08.390052Z"
    }
   },
   "cell_type": "code",
   "source": "#data = make_dataset(xlsx_folder, result_folder, sheet_names)",
   "id": "49825ae9b0d46699",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:28.961654Z",
     "start_time": "2024-08-28T11:36:10.192234Z"
    }
   },
   "cell_type": "code",
   "source": "all_data = load_dataset(\"C:/Users/hamra/PycharmProjects/isolation_forest/data/result\", sheet_names)",
   "id": "954cec12cc6abe9c",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(len(all_data))",
   "id": "b8e1adb3b2740150",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:29.022156Z",
     "start_time": "2024-08-28T11:36:29.000017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that drops rows of the dataset which have null values in specific columns\n",
    "def cleaning(dataframe):\n",
    "    data = copy.deepcopy(dataframe)\n",
    "    all_cols = data.columns\n",
    "    cols = []\n",
    "    for i in range(len(data.columns)):\n",
    "        if(isinstance(data.iloc[0, i], str) or data.iloc[0, i] is np.NaN):\n",
    "            pass\n",
    "        else:\n",
    "            cols.append(data.columns[i])\n",
    "    data = data.dropna(subset = cols)\n",
    "    data = data[cleaning_condition]\n",
    "    print(cols)\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "    return data"
   ],
   "id": "429a750cc3c0f3a",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:36:29.032129Z",
     "start_time": "2024-08-28T11:36:29.022156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(dataframe):\n",
    "    return pd.DataFrame(data = MaxAbsScaler().fit_transform(dataframe))"
   ],
   "id": "4cf1967114f932db",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "row_data = {}\n",
    "data = {}\n",
    "for sheet in sheet_names:\n",
    "    row_data[sheet] = cleaning(all_data[sheet])\n",
    "    data[sheet] = copy.deepcopy(row_data[sheet])"
   ],
   "id": "736fcac3fa6d38eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_data[test_sheet]",
   "id": "4960d3e9e84eb040",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "row_data[test_sheet]",
   "id": "9021136d68a9e143",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Replace string and null values in dataframes with 1 then normalizing them\n",
    "for sheet in sheet_names:\n",
    "    all_values = np.array([])\n",
    "    for i in range(len(data[sheet].columns)):\n",
    "        if(isinstance(data[sheet].iloc[0, i], str) or data[sheet].iloc[0, i] is np.NaN):\n",
    "            col = data[sheet].columns[i]\n",
    "            data[sheet].loc[:, col] = 1\n",
    "            col_values = row_data[sheet][col].unique()\n",
    "            all_values = np.concatenate((all_values, col_values))\n",
    "    all_values = list(all_values)\n",
    "    targets = list(np.full(len(all_values), 1))\n",
    "    map = {all_values[i]: targets[i] for i in range(len(targets))}\n",
    "    for item in list(map.keys()):\n",
    "        pass\n",
    "    data[sheet] = normalize(data[sheet])\n",
    "data[test_sheet]"
   ],
   "id": "1df8b132bdc2ce84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:37:01.535173Z",
     "start_time": "2024-08-28T11:37:01.528279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#in this block we implement last block with ordinal encoder\n",
    "#for sheet in sheet_names:\n",
    "#    cols = []\n",
    "#    for i in range(len(data[sheet].columns)):\n",
    "#        if(isinstance(data[sheet].iloc[0, i], str) or data[sheet].iloc[0, i] is np.NaN):\n",
    "#            cols.append(data[sheet].columns[i])\n",
    "#    data[sheet][cols] = OrdinalEncoder(encoded_missing_value = -0.5).fit_transform(data[sheet][cols])\n",
    "#data[test_sheet]"
   ],
   "id": "12d7f11e72ee3df9",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Run the isolation forest algorithm on all sheets and show some results of the test sheet\n",
    "#model = isolation_forest_algorithm.isolation_forest_algorithm(data[test_sheet], 0.01, flag = True)\n",
    "#model.detection()\n",
    "results = {}\n",
    "for sheet in sheet_names:\n",
    "    if(sheet == test_sheet):\n",
    "        model = isolation_forest_algorithm.isolation_forest_algorithm(row_data[sheet], data[sheet], 0.01, flag = True)\n",
    "    else:\n",
    "        model = isolation_forest_algorithm.isolation_forest_algorithm(row_data[sheet], data[sheet], 0.01)\n",
    "    results[sheet] = model.detection()\n",
    "print(results)"
   ],
   "id": "ef2a6efdc36993e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d5a1e4396bbe0f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
