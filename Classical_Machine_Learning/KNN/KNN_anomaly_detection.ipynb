{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:59:55.542246Z",
     "start_time": "2024-08-31T03:59:55.532098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Import necessary libraries\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from utils import KNN_algorithm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:59:56.230535Z",
     "start_time": "2024-08-31T03:59:56.223613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#path of folders and datasets\n",
    "sheet_names = []\n",
    "xlsx_folder = None\n",
    "result_folder = None"
   ],
   "id": "a4efb1e35ed12e4d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:59:57.008613Z",
     "start_time": "2024-08-31T03:59:56.995759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#parameters\n",
    "test_sheet = None"
   ],
   "id": "387883f7874af1fe",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:59:57.613438Z",
     "start_time": "2024-08-31T03:59:57.590757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that makes csv datasets from multi-sheet excels\n",
    "def make_dataset(input_folder, output_folder, sheet_names):\n",
    "    contents = os.listdir(input_folder)\n",
    "    root = input_folder\n",
    "    total_data = {}\n",
    "    for sheet in sheet_names:\n",
    "        total_data[sheet] = pd.DataFrame()\n",
    "    for content in contents:\n",
    "        adr = root + \"/\" + content\n",
    "        if(os.path.isfile(adr)):\n",
    "            file_data = pd.read_excel(adr, sheet_name = sheet_names)\n",
    "            for sheet in sheet_names:\n",
    "                total_data[sheet] = pd.concat([total_data[sheet], file_data[sheet]])\n",
    "    for sheet in sheet_names:\n",
    "        total_data[sheet] = total_data[sheet].reset_index(drop = True)\n",
    "        total_data[sheet].to_csv(output_folder + \"/\" + sheet + \".csv\", index = False)\n",
    "    return total_data"
   ],
   "id": "f3da626369e3e5a3",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:59:58.337633Z",
     "start_time": "2024-08-31T03:59:58.323196Z"
    }
   },
   "cell_type": "code",
   "source": "#data = make_dataset(xlsx_folder, result_folder, sheet_names)",
   "id": "40d4e029967da5ec",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:59:58.835950Z",
     "start_time": "2024-08-31T03:59:58.816652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that loads all sheet datasets from csv files and puts them in a dict\n",
    "def load_dataset(data_folder, sheet_names):\n",
    "    data = {}\n",
    "    for sheet in sheet_names:\n",
    "        path = data_folder + \"/\" + sheet + \".csv\"\n",
    "        data[sheet] = pd.read_csv(path, low_memory=False).sample(frac = 1).reset_index(drop = True)\n",
    "    return data"
   ],
   "id": "ee839f136c0bc9bd",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T04:00:20.207343Z",
     "start_time": "2024-08-31T03:59:59.581373Z"
    }
   },
   "cell_type": "code",
   "source": "all_data = load_dataset(\"C:/Users/hamra/PycharmProjects/KNN/data/result\", sheet_names)",
   "id": "3bd9e182a84cc831",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(len(all_data))",
   "id": "aeeb7799bced35fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T04:00:23.309653Z",
     "start_time": "2024-08-31T04:00:23.285346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that drops rows of the dataset which have null values in specific columns\n",
    "def cleaning(dataframe):\n",
    "    data = copy.deepcopy(dataframe)\n",
    "    cols = []\n",
    "    for i in range(len(data.columns)):\n",
    "        if(isinstance(data.iloc[0, i], str) or data.iloc[0, i] is np.NaN):\n",
    "            pass\n",
    "        else:\n",
    "            cols.append(data.columns[i])\n",
    "    data = data.dropna(subset = cols)\n",
    "    print(cols)\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "    return data"
   ],
   "id": "7f65d03b8237f47b",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T04:00:24.295098Z",
     "start_time": "2024-08-31T04:00:24.286385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(dataframe):\n",
    "    return pd.DataFrame(data = MaxAbsScaler().fit_transform(dataframe))"
   ],
   "id": "79f111398338769a",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "row_data = {}\n",
    "data = {}\n",
    "for sheet in sheet_names:\n",
    "    row_data[sheet] = cleaning(all_data[sheet])\n",
    "    data[sheet] = copy.deepcopy(row_data[sheet])"
   ],
   "id": "4b32334979a928af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_data[test_sheet]",
   "id": "ec9970a7a56b52b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "row_data[test_sheet]",
   "id": "693b707aae8d20bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Replace string and null values in dataframes with 1 then normalizing them\n",
    "for sheet in sheet_names:\n",
    "    all_values = np.array([])\n",
    "    for i in range(len(data[sheet].columns)):\n",
    "        if(isinstance(data[sheet].iloc[0, i], str) or data[sheet].iloc[0, i] is np.NaN):\n",
    "            col = data[sheet].columns[i]\n",
    "            data[sheet].loc[:, col] = 1\n",
    "            col_values = row_data[sheet][col].unique()\n",
    "            all_values = np.concatenate((all_values, col_values))\n",
    "    all_values = list(all_values)\n",
    "    targets = list(np.full(len(all_values), 1))\n",
    "    map = {all_values[i]: targets[i] for i in range(len(targets))}\n",
    "    for item in list(map.keys()):\n",
    "        pass\n",
    "    data[sheet] = normalize(data[sheet])\n",
    "data[test_sheet]"
   ],
   "id": "b6efcec9e6e103c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Run an algorithm on all sheets and show some results of the test sheet\n",
    "results = {}\n",
    "for sheet in sheet_names:\n",
    "    if(sheet == test_sheet):\n",
    "        model = KNN_algorithm.knn(row_data[sheet], data[sheet], flag = True)\n",
    "    else:\n",
    "        model = KNN_algorithm.knn(row_data[sheet], data[sheet])\n",
    "    results[sheet] = model.detection()\n",
    "print(results)"
   ],
   "id": "72e12a6f4d35e0ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a5924de762d547a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
