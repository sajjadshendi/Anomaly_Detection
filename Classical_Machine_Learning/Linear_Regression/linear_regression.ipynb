{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:52:51.036972Z",
     "start_time": "2024-09-08T04:52:50.989884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Import necessary libraries\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from utils import lin_reg_alg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:52:51.389827Z",
     "start_time": "2024-09-08T04:52:51.371151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#path of folders and datasets\n",
    "sheet_names = []\n",
    "xlsx_dolder = None\n",
    "result_folder = None"
   ],
   "id": "73ee0c8a11ad858c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:52:51.580730Z",
     "start_time": "2024-09-08T04:52:51.568470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#parameters\n",
    "minimum_threshold = 70\n",
    "percentile_threshold = 99\n",
    "test_sheet = None"
   ],
   "id": "316b0a3a9b93e6f0",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:52:51.895050Z",
     "start_time": "2024-09-08T04:52:51.888115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that makes csv datasets from multi-sheet excels\n",
    "def make_dataset(input_folder, output_folder, sheet_names):\n",
    "    contents = os.listdir(input_folder)\n",
    "    root = input_folder\n",
    "    total_data = {}\n",
    "    for sheet in sheet_names:\n",
    "        total_data[sheet] = pd.DataFrame()\n",
    "    for content in contents:\n",
    "        adr = root + \"/\" + content\n",
    "        if(os.path.isfile(adr)):\n",
    "            file_data = pd.read_excel(adr, sheet_name = sheet_names)\n",
    "            for sheet in sheet_names:\n",
    "                total_data[sheet] = pd.concat([total_data[sheet], file_data[sheet]])\n",
    "    for sheet in sheet_names:\n",
    "        total_data[sheet] = total_data[sheet].reset_index(drop = True)\n",
    "        total_data[sheet].to_csv(output_folder + \"/\" + sheet + \".csv\", index = False)\n",
    "    return total_data"
   ],
   "id": "e43d0c7171656144",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:52:52.064836Z",
     "start_time": "2024-09-08T04:52:52.051353Z"
    }
   },
   "cell_type": "code",
   "source": "#data = make_dataset(xlsx_folder, result_folder, sheet_names)",
   "id": "8910a198bd759029",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:52:52.248290Z",
     "start_time": "2024-09-08T04:52:52.242325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that loads all sheet datasets from csv files and puts them in a dict\n",
    "def load_dataset(data_folder, sheet_names):\n",
    "    data = {}\n",
    "    for sheet in sheet_names:\n",
    "        path = data_folder + \"/\" + sheet + \".csv\"\n",
    "        #without shuffling\n",
    "        #data[sheet] = pd.read_csv(path, low_memory=False)\n",
    "        #with shuffling\n",
    "        data[sheet] = pd.read_csv(path, low_memory=False).sample(frac = 1).reset_index(drop = True)\n",
    "    return data"
   ],
   "id": "ac39b74e986d91d8",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:53:12.716446Z",
     "start_time": "2024-09-08T04:52:52.463813Z"
    }
   },
   "cell_type": "code",
   "source": "all_data = load_dataset(result_folder, sheet_names)",
   "id": "ae2b239a43f9a354",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(len(all_data))",
   "id": "115df0b33e41ecc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:53:12.760295Z",
     "start_time": "2024-09-08T04:53:12.741095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#A function that drops rows of the dataset which have null values in specific columns\n",
    "def cleaning(dataframe):\n",
    "    data = copy.deepcopy(dataframe)\n",
    "    cols = []\n",
    "    for i in range(len(data.columns)):\n",
    "        if(isinstance(data.iloc[0, i], str) or data.iloc[0, i] is np.NaN):\n",
    "            pass\n",
    "        else:\n",
    "            cols.append(data.columns[i])\n",
    "    data = data.dropna(subset = cols)\n",
    "    print(cols)\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "    return data"
   ],
   "id": "2010a897717285f1",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T04:53:12.768271Z",
     "start_time": "2024-09-08T04:53:12.760938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(dataframe):\n",
    "    return pd.DataFrame(data = MaxAbsScaler().fit_transform(dataframe))"
   ],
   "id": "a75b53aecce38bf9",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "row_data = {}\n",
    "data = {}\n",
    "for sheet in sheet_names:\n",
    "    row_data[sheet] = cleaning(all_data[sheet])\n",
    "    data[sheet] = copy.deepcopy(row_data[sheet])"
   ],
   "id": "a22784b7f4053d3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_data[test_sheet]",
   "id": "48d3b9f3b510f411",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "row_data[test_sheet]",
   "id": "4bf36b9baff82473",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Replace string and null values in dataframes with 1 then normalizing them\n",
    "for sheet in sheet_names:\n",
    "    all_values = np.array([])\n",
    "    for i in range(len(data[sheet].columns)):\n",
    "        if(isinstance(data[sheet].iloc[0, i], str) or data[sheet].iloc[0, i] is np.NaN):\n",
    "            col = data[sheet].columns[i]\n",
    "            data[sheet].loc[:, col] = 1\n",
    "            col_values = row_data[sheet][col].unique()\n",
    "            all_values = np.concatenate((all_values, col_values))\n",
    "    all_values = list(all_values)\n",
    "    targets = list(np.full(len(all_values), 1))\n",
    "    map = {all_values[i]: targets[i] for i in range(len(targets))}\n",
    "    for item in list(map.keys()):\n",
    "        pass\n",
    "    data[sheet] = normalize(data[sheet])\n",
    "data[test_sheet]"
   ],
   "id": "7937358a24d958c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Run the linear regression algorithm on all sheets and show some results of the test sheet\n",
    "results = {}\n",
    "for sheet in sheet_names:\n",
    "    if(sheet == test_sheet):\n",
    "        model = lin_reg_alg.lin_reg_alg(row_data[sheet], data[sheet], minimum_threshold, percentile_threshold, flag = True)\n",
    "    else:\n",
    "        model = lin_reg_alg.lin_reg_alg(row_data[sheet], data[sheet], minimum_threshold, percentile_threshold)\n",
    "    results[sheet] = model.detection()\n",
    "print(results)"
   ],
   "id": "49d286a7a6a80623",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58b471e02fe975e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
